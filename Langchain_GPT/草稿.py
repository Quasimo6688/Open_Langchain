from langchain.chat_models import ChatOpenAI
from langchain.schema import HumanMessage

chat_model = ChatOpenAI(openai_api_key="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",
                        model_name="gpt-3.5-turbo", temperature=0.7)
text_block = """15.1.3 标准单词和词组备注
下列标准单词在通话中具有特定的含义。
一、请认收(向我表示你已经收到并理解该电报)。
二、是的(是的)。
三、同意(批准所申请的行动)。
四、还有(表示电报各部分的间断；用于电文与电报的其他部分无明显区别的情况。如果信息的各个部分
之间没有明显的区别可以使用该词作为信息各部分之间的间隔标志)。
五、另外(表示在非常繁忙的情况下，发布给不同航空器的电报之间的间断)。
六、取消(废除此前所发布的许可)。
七、检查(检查系统或程序，且通常不回答)。
八、可以(批准按指定条件前行)。
九、证实(我是否已经准确地收到了…？或你是否已经准确地收到了本电报？)。
十、联系(与……建立无线电联系)。
十一、正确(你所讲的是正确的)。
十二、更正(在本电报出了一个错误，或所发布的信息本身是错的，正确的内容应当是……)。
十三、作废(当作信息没有发送)。
十四、信号怎样(我所发电报的清晰度如何？)。
十五、我重复一遍(为了表示澄清或强调，我重复一遍)。
十六、守听(收听或调定到某个频率)。
十七、错误或不同意(并非如此，或不允许，或不对)。
十八、请复诵(请向我准确地重复本电报所有或部分内容)。
十九、重新许可(此前发布给你的许可已经变更，这一新的许可将取代刚才的许可或其中部分内容)。
二十、报告(向我传达下列情报)。
二十一、请求(我希望知道……或我希望得到……)。
二十二、收到(我已经收到了你刚才的发话)。
注：任何情况下，不得采用“对”或者“不对”来回答要求复诵的问题。
二十三、再说或重复一遍(请重复你刚才发话的所有内容或下列部分)。
二十四、讲慢点(请降低你的语速)。
二十五、稍等或等待(请等候，我将呼叫你)。
二十六、核实(与发电方进行检查和确认)。
二十七、照办(“将照办”的缩略语，我已经明白了你的电报并将按照该电报执行)。
二十八、讲两遍。
1.对于申请来说：通信困难，请把每个词(组)发送两遍。
2.对于信息来说：因为通信困难，该电报的每个词(组)将被发送两遍。
样题
如果航空器驾驶员在报告的过程中出现错误并立即修改时，应说的标准词为？"""
formatted_prompt = (
        "提取文档中某一个段落的内容，理解它并将它设计成一个选择题，每题有四个选项（A、B、C）。请按照以下格式提供每个问题的信息：\n"
        "- title: 根据文档中的某个段落随机编写一道选择题，注意这里写入的不是一个简短的标题而是一个引用自文档中某段原文改写而来的完整的问题，题目和答案之间的对应关系应当清洗明确\n"
        "- type: 题目类型，例如 '单选题'\n"
        "- option_list: 一个包含三个选项的列表，每个选项都是一个字典，包含 'content' 和 'id' 键。例如: "
        '[{"content":"选项A内容","id":"A"}, {"content":"选项B内容","id":"B"}, {"content":"选项C内容","id":"C"}，'
        ' {"content":"选项D内容","id":"C"}]\n'
        "- answer: 正确答案的ID，例如 'A'\n"
        "- explain: 答案解释\n"
        "- del_flag: 删除标志，用于表示题目是否已被删除，例如 '0' 代表未删除\n"
        "- create_by: 题目创建者，例如 'admin'\n"
        "- create_time: 题目创建时间，格式为 'MM/DD/YYYY HH:MM:SS'\n"
        "- update_by: 题目最后更新者，例如 'admin'\n"
        "- update_time: 题目最后更新时间，格式为 'MM/DD/YYYY HH:MM:SS'\n\n"
        "这里是知识点内容：\n"
        f"{text_block}"
    )
prompt = formatted_prompt
messages = [HumanMessage(content=prompt)]
response = chat_model.invoke(messages, )
print(response.content)
